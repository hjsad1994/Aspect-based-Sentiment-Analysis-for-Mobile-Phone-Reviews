import pandas as pd
import numpy as np
from collections import Counter
import re
import sys
from collections import defaultdict
from pathlib import Path
from typing import List, Dict

def clean_text(text):
    # Clean text for comparison
    if pd.isna(text):
        return ""
    
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text

def check_duplicates(csv_file):
    print("üîç ƒêang ƒë·ªçc file CSV...")
    
    try:
        df = pd.read_csv(csv_file, encoding='utf-8')
        print(f"‚úÖ ƒê·ªçc th√†nh c√¥ng file CSV")
        print(f"üìä T·ªïng s·ªë d√≤ng: {len(df)}")
        print(f"üìä T·ªïng s·ªë c·ªôt: {len(df.columns)}")
        print(f"üìä T√™n c√°c c·ªôt: {list(df.columns)}")
        
        if 'data' not in df.columns:
            print("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt 'data' trong file CSV")
            return
        
        print(f"\nüîç Ph√¢n t√≠ch d·ªØ li·ªáu tr√πng l·∫∑p...")
        
        # Check exact duplicates
        print("\n1Ô∏è‚É£ KI·ªÇM TRA TR√ôNG L·∫∂P HO√ÄN TO√ÄN:")
        exact_duplicates = df.duplicated(subset=['data'], keep=False)
        exact_duplicate_count = exact_duplicates.sum()
        
        if exact_duplicate_count > 0:
            print(f"‚ö†Ô∏è  T√¨m th·∫•y {exact_duplicate_count} d√≤ng b·ªã tr√πng l·∫∑p ho√†n to√†n")
            
            duplicate_rows = df[exact_duplicates]
            duplicate_groups = duplicate_rows.groupby('data').size().sort_values(ascending=False)
            
            print(f"üìã Chi ti·∫øt c√°c nh√≥m tr√πng l·∫∑p:")
            for i, (content, count) in enumerate(duplicate_groups.head(10).items(), 1):
                print(f"   {i}. Xu·∫•t hi·ªán {count} l·∫ßn:")
                print(f"      \"{content[:100]}{'...' if len(str(content)) > 100 else ''}\"")
                print()
        else:
            print("‚úÖ Kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p ho√†n to√†n")
        
        # Create clean data
        print("\n2Ô∏è‚É£ T·∫†O D·ªÆ LI·ªÜU S·∫†CH (LO·∫†I B·ªé DUMP):")
        
        clean_df = df[~df.duplicated(subset=['data'], keep='first')].copy()
        clean_count = len(clean_df)
        removed_count = len(df) - clean_count
        
        print(f"üìä S·ªë d√≤ng sau khi lo·∫°i b·ªè dump: {clean_count}")
        print(f"üìä S·ªë d√≤ng ƒë√£ lo·∫°i b·ªè: {removed_count}")
        print(f"üìä T·ª∑ l·ªá d·ªØ li·ªáu s·∫°ch: {(clean_count / len(df)) * 100:.2f}%")
        
        # Statistics
        print("\n3Ô∏è‚É£ TH·ªêNG K√ä T·ªîNG QUAN:")
        print(f"üìä T·ªïng s·ªë d√≤ng g·ªëc: {len(df)}")
        print(f"üìä S·ªë d√≤ng tr√πng l·∫∑p (dump): {exact_duplicate_count}")
        print(f"üìä S·ªë d√≤ng duy nh·∫•t (s·∫°ch): {clean_count}")
        print(f"üìä T·ª∑ l·ªá dump: {(exact_duplicate_count / len(df)) * 100:.2f}%")
        print(f"üìä T·ª∑ l·ªá d·ªØ li·ªáu s·∫°ch: {(clean_count / len(df)) * 100:.2f}%")
        
        # Check empty data
        print("\n4Ô∏è‚É£ KI·ªÇM TRA D·ªÆ LI·ªÜU TR·ªêNG:")
        empty_count = df['data'].isna().sum()
        empty_string_count = (df['data'] == '').sum()
        print(f"üìä S·ªë d√≤ng c√≥ gi√° tr·ªã null: {empty_count}")
        print(f"üìä S·ªë d√≤ng c√≥ chu·ªói r·ªóng: {empty_string_count}")
        
        # Save results
        print("\n5Ô∏è‚É£ L∆ØU K·∫æT QU·∫¢:")
        
        if exact_duplicate_count > 0:
            frequency_count = df['data'].value_counts()
            frequency_df = pd.DataFrame({
                'content': frequency_count.index,
                'frequency': frequency_count.values
            })
            
            duplicates_only = frequency_df[frequency_df['frequency'] > 1].copy()
            duplicates_only = duplicates_only.sort_values('frequency', ascending=False)
            
            duplicates_only.to_csv('duplicates_exact.csv', index=False, encoding='utf-8')
            print("‚úÖ ƒê√£ l∆∞u file 'duplicates_exact.csv' ch·ª©a d·ªØ li·ªáu dump (ƒë√£ s·∫Øp x·∫øp theo t·∫ßn su·∫•t)")
            
            print(f"\nüèÜ TOP 10 D·ªÆ LI·ªÜU DUMP NHI·ªÄU NH·∫§T:")
            for i, row in duplicates_only.head(10).iterrows():
                content = str(row['content'])
                if len(content) > 80:
                    content = content[:80] + "..."
                print(f"   {i+1:2d}. Xu·∫•t hi·ªán {row['frequency']:3d} l·∫ßn: \"{content}\"")
        
        clean_df.to_csv('clean_data.csv', index=False, encoding='utf-8')
        print(f"‚úÖ ƒê√£ l∆∞u file 'clean_data.csv' ch·ª©a {len(clean_df)} d√≤ng d·ªØ li·ªáu s·∫°ch (ƒë√£ lo·∫°i b·ªè dump)")
        
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")

def main():
    DATA_FILE = Path("data") / "Dataset Text Normalization 14k.csv"
    if not DATA_FILE.exists():
        if sys.stdout.encoding != 'utf-8':
            sys.stdout.reconfigure(encoding='utf-8')
        print(f"Kh√¥ng t√¨m th·∫•y file: {DATA_FILE}")
        return

    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')

    print("=" * 60)
    print("üîç KI·ªÇM TRA D·ªÆ LI·ªÜU TR√ôNG L·∫∂P TRONG FILE CSV")
    print("=" * 60)
    
    check_duplicates(DATA_FILE)
    
    print("\n" + "=" * 60)
    print("‚úÖ HO√ÄN TH√ÄNH KI·ªÇM TRA")
    print("=" * 60)

if __name__ == "__main__":
    main()
